# API Design Specification: PromptSculptor API (Prototype v1)

## 1. API Overview

*   **Summary:** This document details the API design for the PromptSculptor prototype (v1). The API provides endpoints for analyzing, remixing, and creating AI prompts programmatically. It is built using Python, FastAPI, SQLModel, and SQLite, following a monolithic architecture pattern. The initial version focuses on core functionality without user authentication. All interactions are stateless, though API calls are logged to a SQLite database for debugging and potential future analysis.
*   **OpenAPI/Swagger:** Documentation will be automatically generated by FastAPI and accessible at `/docs` and `/redoc` relative to the application's base URL once implemented.

## 2. Project Structure

A standard FastAPI project structure will be used:


## 3. Core Dependencies

*   `fastapi`: The core web framework.
*   `uvicorn[standard]`: ASGI server for running the application.
*   `sqlmodel`: ORM for database interaction (integrates Pydantic and SQLAlchemy).
*   `pydantic`: Data validation and settings management.
*   `pydantic-settings`: For managing configuration via environment variables.
*   `sqlite+aiosqlite`: Async driver for SQLite database access (required for non-blocking DB operations in async FastAPI).
*   `httpx`: Async HTTP client for making requests to external LLM APIs.
*   `python-dotenv`: For loading environment variables from a `.env` file during development.
*   `openai` / `anthropic` / etc.: Python client library for the chosen external LLM provider.

## 4. Authentication & Authorization

*   **None for Prototype v1.** All API endpoints (`/analyze`, `/remix`, `/create`) are publicly accessible.

## 5. Pydantic & SQLModel Models

*   **SQLModel (Database):**
    *   `ApiLog` (defined in `Database_Design.md` and located in `app/models/log.py`): Used for logging API requests and responses. Fields: `id`, `timestamp`, `endpoint`, `request_payload`, `response_payload`, `status_code`, `processing_time_ms`.
*   **Pydantic (API Schemas - located in `app/schemas/prompt.py`):**

    ```python
    # app/schemas/prompt.py
    from pydantic import BaseModel, Field
    from typing import List, Optional, Dict, Any

    # --- Analyze ---
    class AnalyzeRequest(BaseModel):
        prompt: str = Field(..., min_length=1, description="The prompt text to analyze.")

    class AnalyzeResponse(BaseModel):
        clarity_score: Optional[int] = Field(None, ge=0, le=100, description="Estimated clarity score (0-100). Calculation TBD.")
        issues: List[str] = Field(default_factory=list, description="List of identified potential issues (e.g., 'Vague', 'Too Long').")
        suggestions: List[str] = Field(default_factory=list, description="Brief suggestions for improvement.")

    # --- Remix ---
    class RemixRequest(BaseModel):
        prompt: str = Field(..., min_length=1, description="The prompt text to remix.")
        styles: Optional[List[str]] = Field(None, description="Optional list of desired remix styles (e.g., 'shorter', 'more_detailed', 'simpler_language').")
        # count: Optional[int] = Field(default=3, ge=1, le=5, description="Number of variations to generate.") # Example optional parameter

    class RemixResponse(BaseModel):
        remixes: List[str] = Field(..., description="List of generated prompt variations.")

    # --- Create ---
    class CreateRequest(BaseModel):
        goal: str = Field(..., description="A description of the desired prompt's goal or purpose.")
        context: Optional[Dict[str, Any]] = Field(None, description="Optional dictionary providing additional context (e.g., target audience, complexity level).")

    class CreateResponse(BaseModel):
        prompt: str = Field(..., description="The generated prompt string.")

    # --- Shared Error Model ---
    class ErrorDetail(BaseModel):
        detail: str
    ```

## 6. API Endpoints

All endpoints will be under the `/api/v1` prefix.

*   **Resource Group: Prompts** (`app/api/endpoints/prompts.py`)

    *   **`POST /api/v1/analyze`**
        *   **Description:** Analyzes a given prompt for clarity and potential issues.
        *   **Request Body:** `AnalyzeRequest`
        *   **Response(s):**
            *   `200 OK`: `AnalyzeResponse` - Analysis successful.
            *   `422 Unprocessable Entity`: `HTTPValidationError` (FastAPI default) - Invalid request body.
            *   `500 Internal Server Error`: `ErrorDetail` - Error during analysis (e.g., LLM API failure).
            *   `503 Service Unavailable`: `ErrorDetail` - External LLM service unavailable.
        *   **Auth:** No
        *   **DB Interaction:** Creates an `ApiLog` entry upon completion (success or failure).

    *   **`POST /api/v1/remix`**
        *   **Description:** Generates variations (remixes) of a given prompt based on optional style parameters.
        *   **Request Body:** `RemixRequest`
        *   **Response(s):**
            *   `200 OK`: `RemixResponse` - Remixes generated successfully.
            *   `422 Unprocessable Entity`: `HTTPValidationError` - Invalid request body.
            *   `500 Internal Server Error`: `ErrorDetail` - Error during remixing.
            *   `503 Service Unavailable`: `ErrorDetail` - External LLM service unavailable.
        *   **Auth:** No
        *   **DB Interaction:** Creates an `ApiLog` entry upon completion.

    *   **`POST /api/v1/create`**
        *   **Description:** Generates a new prompt based on a given goal description and optional context.
        *   **Request Body:** `CreateRequest`
        *   **Response(s):**
            *   `200 OK`: `CreateResponse` - Prompt created successfully.
            *   `422 Unprocessable Entity`: `HTTPValidationError` - Invalid request body.
            *   `500 Internal Server Error`: `ErrorDetail` - Error during creation.
            *   `503 Service Unavailable`: `ErrorDetail` - External LLM service unavailable.
        *   **Auth:** No
        *   **DB Interaction:** Creates an `ApiLog` entry upon completion.

## 7. Error Handling Strategy

*   **Validation Errors:** FastAPI's default handling using Pydantic models will return `422 Unprocessable Entity` responses with detailed error information for invalid request bodies.
*   **Standard HTTP Errors:** Use appropriate status codes (e.g., `404 Not Found` if applicable later, though not for v1 endpoints).
*   **Internal Server Errors:** Generic `500 Internal Server Error` for unexpected issues within the application logic.
*   **External Service Errors:**
    *   Define custom exceptions (e.g., `LLMServiceError`, `LLMApiKeyError`) in `services/llm_service.py`.
    *   Implement FastAPI exception handlers (`@app.exception_handler(...)` in `main.py`) for these custom exceptions.
    *   These handlers will log the detailed error and return appropriate responses, typically:
        *   `503 Service Unavailable` if the external LLM API is unreachable or returns a server-side error.
        *   `500 Internal Server Error` if there's an issue with our configuration (e.g., invalid API key) or unexpected response format.
*   **Logging:** All handled exceptions (including validation errors caught by FastAPI) should ideally result in an `ApiLog` entry being created with the corresponding error status code and potentially a simplified error message in the response payload field.

## 8. Key Asynchronous Operations

*   **API Endpoints:** All FastAPI path operation functions (`analyze`, `remix`, `create`) will be defined using `async def`.
*   **External LLM Calls:** Interactions with the external LLM service (via `httpx` or the provider's async SDK) within `services/llm_service.py` **must** be asynchronous (`await client.post(...)` or similar) to avoid blocking the server's event loop.
*   **Database Operations (Logging):** Writing `ApiLog` entries to the SQLite database will use the `aiosqlite` driver via SQLModel's async session management (`async with AsyncSession(engine) as session: ... await session.add(...)`). This prevents the potentially blocking I/O of writing to the database file from halting other concurrent requests. Standard `sqlite3` is blocking and should not be used directly in async functions without running it in a thread pool executor (which adds complexity). Using `aiosqlite` is the preferred approach with FastAPI/SQLite.

## 9. Future Enhancements (Post-Prototype v1)

Following the successful implementation and evaluation of the v1 prototype, future development phases could include:

*   **Authentication & Authorization:**
    *   Implement API Key authentication managed via an API Gateway (Kong). Clients would need to provide a valid key in their requests.
    *   Potentially add user account management with JWT-based authentication for more granular control and user-specific features (e.g., saved prompts).
*   **Rate Limiting:**
    *   Implement rate limiting per API key/consumer, configured within the API Gateway (Kong), to prevent abuse and manage load.
*   **New Endpoints (Based on PRD):**
    *   **`POST /api/v1/test`**: Test a prompt against multiple LLMs simultaneously.
    *   **`POST /api/v1/contextualize`**: Adapt a prompt based on a specified persona or context.
    *   **`GET /api/v1/history/{prompt_id}`**: Retrieve version history for a specific prompt (requires significant DB changes).
    *   **`POST /api/v1/combine`**: Merge prompt fragments intelligently.
*   **Database Schema Evolution:**
    *   Introduce tables for `Users`, `ApiKeys` (or rely on Kong's consumer management), `Prompts` (for history/saving), `PromptVersions`, etc., as needed to support new features.
    *   Migrate from SQLite to PostgreSQL or similar for scalability.
*   **Enhanced Logging & Monitoring:**
    *   Integrate structured logging with monitoring platforms (e.g., Datadog, Grafana Loki).
    *   Expose application metrics (e.g., request latency, error rates) via Prometheus, potentially integrated through Kong.
*   **Refined LLM Interactions:**
    *   Implement more sophisticated logic for selecting LLMs based on the task.
    *   Add support for more LLM providers.
    *   Improve error handling and retries for external API calls.